#! /bin/bash -x

# Script para recuperar e organizar as informações sobre os dados de
# observaçao armazenadas e disponíveis para a assimilação de dados

# @cfbastarz (25/03/2025)

lpath=/share/das/dist/carlos.bastarz/SMNAMonitoringApp/obsm
dataloggsi=/share/das/dist/carlos.bastarz/SMNAMonitoringApp/logs/gsi
dataloggsioper=/lustre_xc50/ioper/models/SMNA-Oper/SMG/datainout/gsi/dataout

datai=#DATAI#
dataf=#DATAF#

data=${datai}

rm -rf txt csv

if [ ! -d txt ]; then mkdir -v txt; fi
if [ ! -d csv ]; then mkdir -v csv; fi

while [ ${data} -le ${dataf} ]
do

  echo ${data}

  dataobs=/lustre_xc50/ioper/data/external/${data}/dataout/NCEP

  ssh carlos_bastarz@login-xc50.cptec.inpe.br ls -l --full-time ${dataobs} > ${lpath}/txt/obs-tmp_${data}.txt

  # Remove a primeira linha
  sed -i '1d' ${lpath}/txt/obs-tmp_${data}.txt

  # Remove linhas cujos nomes dos arquivos de observação não iniciam com "gdas" ou "gfs",
  # que contém as strings html, sfcanl, atmanl e rtgssthr
  grep -vE '\.gdas\b' ${lpath}/txt/obs-tmp_${data}.txt > ${lpath}/txt/obs-tmp1_${data}.txt
  grep -vE '\.gblav\b' ${lpath}/txt/obs-tmp1_${data}.txt > ${lpath}/txt/obs-tmp2_${data}.txt
  grep -vE '\html\b' ${lpath}/txt/obs-tmp2_${data}.txt > ${lpath}/txt/obs-tmp3_${data}.txt
  grep -vE '\.sfcanl.\b' ${lpath}/txt/obs-tmp3_${data}.txt > ${lpath}/txt/obs-tmp4_${data}.txt
  grep -vE '\.atmanl.\b' ${lpath}/txt/obs-tmp4_${data}.txt > ${lpath}/txt/obs-tmp5_${data}.txt
  grep -vE '\rtgssthr_grb_0.083\b' ${lpath}/txt/obs-tmp5_${data}.txt > ${lpath}/txt/obs-tmp6_${data}.txt
  grep -vE '\rtgssthr_grb_0.5\b' ${lpath}/txt/obs-tmp6_${data}.txt > ${lpath}/txt/obs-tmp7_${data}.txt

  sed -i '/GDAS_/d' ${lpath}/txt/obs-tmp7_${data}.txt
  cat ${lpath}/txt/obs-tmp7_${data}.txt | sed '/oisst/d' > ${lpath}/txt/obs_${data}.txt

  # Conta quantas observações estão disponíveis no arquivo
  nobs=$(cat ${lpath}/txt/obs_${data}.txt | wc -l)

  # Primeira coluna (Tamanho do Download (KB)) - c1
  cat ${lpath}/txt/obs_${data}.txt | awk -F " " '{print $5}' > ${lpath}/txt/obs-c1_${data}.txt

  # Segunda coluna (Data do Download) - c2
  cat ${lpath}/txt/obs_${data}.txt | awk -F " " '{print $6" "$7}' | awk -F "." '{print $1}' > ${lpath}/txt/obs-c2_${data}.txt

  # Terceira coluna (Fuso Horário) - c3
  cat ${lpath}/txt/obs_${data}.txt | awk -F " " '{print $8}' > ${lpath}/txt/obs-c3_${data}.txt

  # Quarta coluna (Nome do Arquivo) - c4
  cat ${lpath}/txt/obs_${data}.txt | awk -F " " '{print $9}' > ${lpath}/txt/obs-c4_${data}.txt

  # Quinta coluna (Início do Ciclo AD) - c5
  loggsi=${dataloggsi}/gsi_${data}.log

  if [ ! -s ${loggsi} ]
  then
    ssh carlos_bastarz@login-xc50.cptec.inpe.br cat ${dataloggsioper}/${data}/gsiStdout_${data}.runTime*.log > ${loggsi}
  fi 

  # Recupera a hora em que o programa principal do GSI iniciou
  if [ -s ${loggsi} ]
  then
    yyyy=$(grep -a "STARTING DATE-TIME" ${loggsi} | awk '{printf $4}' | awk -F "," '{print $2}')
    mm=$(grep -a "STARTING DATE-TIME" ${loggsi} | awk '{printf $3}' | awk 'BEGIN {split("JAN FEB MAR APR MAY JUN JUL AUG SEP OCT NOV DEC", m, " "); for (i=1; i<=12; i++) mm[m[i]]=sprintf("%02d", i);} {for (i in mm) gsub(i, mm[i]); print}')
    dd=$(grep -a "STARTING DATE-TIME" ${loggsi} | awk '{printf $4}' | awk -F "," '{print $1}')
    hh=$(grep -a "STARTING DATE-TIME" ${loggsi} | awk '{printf $5}' | awk -F "." '{print $1}')
    for i in $(seq 1 $nobs); do echo "${yyyy}-${mm}-${dd} ${hh}" >> ${lpath}/txt/obs-c5_${data}.txt; done
  else
    for i in $(seq 1 $nobs); do echo "NaT" >> ${lpath}/txt/obs-c5_${data}.txt; done
  fi

  # Sexta coluna (Tipo de Arquivo) - c6
  cat ${lpath}/txt/obs_${data}.txt | awk -F " " '{print $9}' | awk -F "." '{print $1}' > ${lpath}/txt/obs-c6_${data}.txt

  # Sétima coluna (Horário sinótico) - c7
  cat ${lpath}/txt/obs_${data}.txt | awk -F " " '{print $9}' | awk -F "." '{print $2}' | cut -c2-3 > ${lpath}/txt/obs-c7_${data}.txt

  # Oitava coluna (Tipo de Observação) - c8
  cat ${lpath}/txt/obs_${data}.txt | awk -F " " '{print $9}' | awk -F "." '{print $3}' > ${lpath}/txt/obs-c8_${data}.txt

  # Nona coluna (Data da Observação) - c9
  cat ${lpath}/txt/obs_${data}.txt | awk -F " " '{print $9}' | awk -F "." '{print $NF""$2}' | tr -d 'tz' | awk '{print substr($0,1,4) "-" substr($0,5,2) "-" substr($0,7,2) " " substr($0,9,2) ":00:00"}' > ${lpath}/txt/obs-c9_${data}.txt

  # Concatena todos os arquivos
  paste -d "," ${lpath}/txt/obs-c{1..9}_${data}.txt > ${lpath}/csv/mon_rec_obs_${data}.csv

  data=$(date -d "${data:0:8} ${data:8:2}00 +6 hours" +"%Y%m%d%H")

done

cat $(ls ${lpath}/csv/mon_rec_obs_*.csv | sort) > ${lpath}/mon_rec_obs_final.csv

sed -i '1 i\Tamanho do Download (KB),Data do Download,Fuso Horário,Nome do Arquivo,Início do Ciclo AD,Tipo de Arquivo,Horário Sinótico,Tipo de Observação,Data da Observação' ${lpath}/mon_rec_obs_final.csv

exit 0
